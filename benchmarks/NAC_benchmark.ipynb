{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAC coloring search\n",
    "\n",
    "In this notebook we provide utils to run benchmarks and experiment with our code.\n",
    "\n",
    "In the first section we start with utility functions, in the second part we load/generate benchmark data. After we run individual benchmarks on selected graph classes with selected algorithms. The algorithms are described in that section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using VScode, add this option to your `.vscode/settings.json` file.\n",
    "```json\n",
    "{\n",
    "    \"jupyter.notebookFileRoot\": \"${workspaceFolder}\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict, deque\n",
    "import random\n",
    "import importlib\n",
    "from random import Random\n",
    "from enum import Enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline as backend_inline\n",
    "from matplotlib.backends import backend_agg\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import signal\n",
    "import itertools\n",
    "import base64\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nac as nac\n",
    "import nac.util\n",
    "from nac import MonochromaticClassType\n",
    "\n",
    "import benchmarks\n",
    "from benchmarks import dataset\n",
    "from benchmarks import generators\n",
    "import benchmarks.notebook_utils\n",
    "from benchmarks.notebook_utils import *\n",
    "\n",
    "seed=42\n",
    "TEST=False\n",
    "BENCHMARKS=False\n",
    "ANALYTICS=False\n",
    "SEARCH=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(nac)\n",
    "importlib.reload(nac.util)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(generators)\n",
    "importlib.reload(benchmarks)\n",
    "importlib.reload(benchmarks.notebook_utils)\n",
    "\n",
    "_BENCH_FILE_START_V2 = \"bench_res_v2\"\n",
    "_BENCH_FILE_START_V3 = \"bench_res_v3\"\n",
    "_BENCH_FILE_START_V4 = \"bench_res_v4\"\n",
    "\n",
    "OUTPUT_DIR = os.path.join(\"benchmarks\", \"runs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "benchmarks.notebook_utils.OUTPUT_DIR = OUTPUT_DIR\n",
    "benchmarks.notebook_utils.OUTPUT_BENCH_FILE_START = _BENCH_FILE_START_V4\n",
    "benchmarks.notebook_utils.OUTPUT_VERBOSE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading locally stored graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graphs:\n",
    "    \"\"\"\n",
    "    Randomly generated laman graphs of various sizes\n",
    "    \"\"\"\n",
    "    laman_random = LazyList(lambda: dataset.load_laman_random_graphs())\n",
    "    \"\"\"\n",
    "    Graphs with no 3 nor 4 cycles up to 42 vertices\n",
    "    \"\"\"\n",
    "    no_3_nor_4_cycles = LazyList(lambda: dataset.load_no_3_nor_4_cycle_graphs())\n",
    "    \"\"\"\n",
    "    Graphs generated according to yet unpublished formula that guaranties that these graphs should either have none or small number of NAC-colorings\n",
    "    \"\"\"\n",
    "    sparse_with_few_colorings = LazyList(lambda: dataset.load_sparse_with_few_colorings_graphs())\n",
    "    \"\"\"\n",
    "    Globally rigid graphs\n",
    "    \"\"\"\n",
    "    globally_rigid = LazyList(lambda: dataset.load_globally_rigid_graphs())\n",
    "    \"\"\"\n",
    "    Graphs gathered from other cathegories that have no NAC-coloring and more than one triangle-connected component\n",
    "    \"\"\"\n",
    "    no_NAC_coloring_gathered = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_gathered())\n",
    "    \"\"\"\n",
    "    Random (globally rigid) graphs that have no NAC-coloring and more than 2*sqrt(n) triangle-connected components\n",
    "    \"\"\"\n",
    "    no_NAC_coloring_generated_40 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(40))\n",
    "    no_NAC_coloring_generated_50 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(50))\n",
    "    no_NAC_coloring_generated_60 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(60))\n",
    "    no_NAC_coloring_generated_70 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(70))\n",
    "    no_NAC_coloring_generated_80 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(80))\n",
    "    no_NAC_coloring_generated_90 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(90))\n",
    "    no_NAC_coloring_generated_100 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(100))\n",
    "    no_NAC_coloring_generated_110 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(110))\n",
    "    no_NAC_coloring_generated_120 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(120))\n",
    "    no_NAC_coloring_generated_130 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(130))\n",
    "\n",
    "    laman_nauty = LazyList(lambda: dataset.load_laman_graphs())\n",
    "    laman_deg_3_plus = LazyList(lambda: dataset.load_laman_degree_3_plus())\n",
    "    sparse_graphs = LazyList(lambda: (\n",
    "        dataset.generate_sparse_graphs(30, 40, count=64) +\n",
    "        dataset.generate_sparse_graphs(40, 50, count=32) +\n",
    "        dataset.generate_sparse_graphs(50, 60, count=16) +\n",
    "        dataset.generate_sparse_graphs(60, 70, count=8)\n",
    "    ))\n",
    "\n",
    "    \"\"\"\n",
    "    Loads all the Laman graphs of the given size, pregenerated files allow the range of [5, 11]\n",
    "    In case you want to use it in benchmarks, list all the graphs first.\n",
    "    \"\"\"\n",
    "    def load_all_laman(vertex_no: int) -> Iterator[nx.Graph]:\n",
    "        return dataset.load_laman_all(vertices_no=vertex_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell bellow generates random laman graphs and stores them as `./benchmarks/graph-store/laman-random/laman_{n}.g6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = defaultdict(list)\n",
    "# for graph in Graphs.globally_rigid:\n",
    "#     mapping[graph.number_of_nodes()].append(graph)\n",
    "# display([(k, len(v)) for k, v in sorted(mapping.items())])\n",
    "# for k, v in sorted(mapping.items()):\n",
    "#     path = os.path.join(dataset.RANDOM_DIR, f\"globally_rigid\")\n",
    "#     os.makedirs(path, exist_ok=True)\n",
    "#     name = f\"globally_rigid_{k}.g6\"\n",
    "#     path = os.path.join(path, name)\n",
    "#     generators._write_graphs_to_file(path, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and loading benchmark results\n",
    "\n",
    "Each row represents performance of a graph with a given strategy.\n",
    "The difference between the first and all variant is that\n",
    "in the all variants we search for all NAC-colorings,\n",
    "but in the first variant we search only.\n",
    "\n",
    "The export CSV columns are:\n",
    "- `timestamp` - date time of the test in UTC\n",
    "- `graph` - base64 encoded bytes of graph6 encoded graph\n",
    "- `dataset` - class of the graph, `minimally_ridig_random`, `no_3_nor_4_cycles`, `globally_rigid`, ...\n",
    "- `vertex_no` - the number of vertices of the graph\n",
    "- `edge_no` - the number of edges of the graph\n",
    "- `triangle_components_no` - the number of triangle components of the graph\n",
    "- `monochromatic_classes_no` - the number of monochromatic classes of the graph\n",
    "- `relabel` - relabel strategy (relabels vertices before the main algorithm is run, here we have only `none` or `random`)\n",
    "- `split` - splitting strategy\n",
    "- `merge` - merging strategy\n",
    "- `subgraph_size` - the target initial size of subgraphs in monochromatic components\n",
    "- `used_monochromatic_classes` - if monochromatic classes were used to run the test, `False` means triangle components were used\n",
    "- `nac_any_finished` - if any of the tests finished in time\n",
    "- `nac_{first|all}_coloring_no` - the number of NAC-colorings of the graph, for the first variant limited to 1\n",
    "- `nac_{first|all}_mean_time` - the time required to find first/all NAC-colorings in milliseconds\n",
    "- `nac_{first|all}_rounds` - the number of rounds used to run the benchmarks\n",
    "- `nac_{first|all}_check_cycle_mask` - the number of cycle mask checks performed\n",
    "- `nac_{first|all}_check_is_NAC` - the number of `IsNACColorng` checks performed\n",
    "- `nac_{first|all}_merge` - the number of merges performed\n",
    "- `nac_{first|all}_merge_no_common_vertex` - the number of merges with no common vertex (these are simple to compute, but produce large no of colorings slowing down the algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Promising:\n",
    "    RELABELING = [\n",
    "        \"none\",\n",
    "        # \"random\",\n",
    "        # \"bfs\",\n",
    "    ]\n",
    "    SPLITTING = [\n",
    "        \"none\",\n",
    "        # \"cycles_match_chunks\",\n",
    "        \"neighbors\",\n",
    "        # \"neighbors_degree\",\n",
    "        # \"beam_neighbors\",\n",
    "    ]\n",
    "    MERGING_OFFLINE = [\n",
    "        \"linear\",\n",
    "        # \"score\",\n",
    "        # \"shared_vertices\",\n",
    "        # \"sorted_size\",\n",
    "    ]\n",
    "    MERGING_ONLINE = [\n",
    "        \"linear\",\n",
    "        # \"shared_vertices\",\n",
    "        # \"sorted_size\",\n",
    "    ]\n",
    "    SIZES = [4] # [4, 5, 6, 7]\n",
    "\n",
    "    strategies_offline = list(itertools.product(\n",
    "        RELABELING, SPLITTING, MERGING_OFFLINE, SIZES,\n",
    "    ))\n",
    "    strategies_online = list(itertools.product(\n",
    "        RELABELING, SPLITTING, MERGING_ONLINE, SIZES,\n",
    "    ))\n",
    "print(f\"Offline strategies: {len(Promising.strategies_offline)}\")\n",
    "print(f\"Online strategies:  {len(Promising.strategies_online)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File storage management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_DataFrame(data: List[MeasurementResult] = []) -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        [x.to_list() for x in data],\n",
    "        columns=COLUMNS,\n",
    "    )\n",
    "\n",
    "def update_stored_data(dfs: List[pd.DataFrame] = [], head_loaded: bool = True) -> pd.DataFrame:\n",
    "    df = load_records()\n",
    "    if head_loaded:\n",
    "        display(df)\n",
    "    if len(dfs) != 0:\n",
    "        df = pd.concat((df, pd.concat(dfs)))\n",
    "    df = df.drop_duplicates(\n",
    "        subset=[\"graph\", \"dataset\", \"split\", \"relabel\", \"merging\", \"subgraph_size\", \"use_smart_split\", \"used_monochromatic_classes\"],\n",
    "        keep='last',\n",
    "    )\n",
    "    store_results(df)\n",
    "    return df\n",
    "\n",
    "def migrate_v2_to_v3(dir = OUTPUT_DIR) -> pd.DataFrame:\n",
    "    file_name_v2 = find_latest_record_file(_BENCH_FILE_START_V2, dir)\n",
    "    path = os.path.join(dir, file_name_v2)\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"use_smart_split\"] = True\n",
    "    df[\"used_monochromatic_classes\"] = True\n",
    "    df.loc[df[\"dataset\"] == 'laman_random_no_smart_split', \"use_smart_split\"] = False\n",
    "    df.loc[df[\"dataset\"] == 'laman_random_no_smart_split', \"dataset\"] = 'laman_random'\n",
    "    df = df[COLUMNS]\n",
    "    store_results(df, None, dir)\n",
    "\n",
    "def migrate_v3_to_v4(dir = OUTPUT_DIR) -> pd.DataFrame:\n",
    "    file_name_v3 = find_latest_record_file(_BENCH_FILE_START_V3, dir)\n",
    "    path = os.path.join(dir, file_name_v3)\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"timestamp\"] = datetime.datetime(1970, 1, 1)\n",
    "    df[\"nac_first_merge\"] = -1\n",
    "    df[\"nac_first_merge_no_common_vertex\"] = -1\n",
    "    df[\"nac_all_merge\"] = -1\n",
    "    df[\"nac_all_merge_no_common_vertex\"] = -1\n",
    "    df = df[COLUMNS]\n",
    "    store_results(df, None, dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running and recording benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_strategy(param: Tuple[str, str, str, int], use_smart_split: bool) -> Tuple[str, str]:\n",
    "    relabel, split, merge, subgraph = param\n",
    "    algo_name = \"subgraphs-{}-{}-{}{}\".format(\n",
    "        merge, split, subgraph, \"-smart\" if use_smart_split else \"\"\n",
    "    )\n",
    "    return (relabel, algo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_for_graph_class(\n",
    "    dataset_name: str,\n",
    "    graphs: Iterable[nx.Graph],\n",
    "    all_max_vertex_no: int,\n",
    "    rounds:int,\n",
    "    graph_timeout: int,\n",
    "    use_smart_split: bool = True,\n",
    "    use_monochromatic_classes: bool = True,\n",
    "    df_seen: pd.DataFrame | None = load_records(),\n",
    "    save_every: int | None = 5*60,\n",
    "    cycles_all_max_vertices: int = 20,\n",
    "    cycles_first_max_vertices: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs benchmarks for the given graph class.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_name: Name of the dataset stored in the output csv\n",
    "        graphs: Iterable of graphs to benchmark\n",
    "        all_max_vertex_no: Maximum vertex number to search for all NAC-colorings\n",
    "        rounds: Number of rounds to run for each graph\n",
    "        graph_timeout: Timeout for each graph in seconds\n",
    "        use_monochromatic_classes: Whether to use monochromatic classes or tiriangle connected components\n",
    "        df_seen: Dataframe with already measured data, so already tried graphs and strategies can be skipped\n",
    "        save_every: save progress every number of seconds\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    dataset_name = dataset_name.replace(\" \", \"_\").lower()\n",
    "    if df_seen is None:\n",
    "        df_seen = new_DataFrame()\n",
    "    df_seen = df_seen.query(f\"dataset == '{dataset_name}'\")\n",
    "\n",
    "    results: List[MeasurementResult] = []\n",
    "    all_results: List[MeasurementResult] = []\n",
    "\n",
    "    last_save = time.time()\n",
    "\n",
    "    for graph in tqdm(graphs):\n",
    "        # this would be a functin if python would not have broken scoping\n",
    "        if save_every is not None:\n",
    "            now = time.time()\n",
    "            if now - last_save > save_every:\n",
    "                all_results.extend(results)\n",
    "                df = new_DataFrame(results)\n",
    "                update_stored_data([df], head_loaded=False)\n",
    "                results = []\n",
    "                last_save = now\n",
    "\n",
    "\n",
    "        all_colorings = all_max_vertex_no >= graph.number_of_nodes()\n",
    "        trianlge_classes = len(nac.find_monochromatic_classes(graph=graph, class_type=MonochromaticClassType.TRIANGLES)[1])\n",
    "        monochromatic_classes = len(nac.find_monochromatic_classes(graph=graph, class_type=MonochromaticClassType.MONOCHROMATIC)[1])\n",
    "\n",
    "        strategies = Promising.strategies_offline if all_colorings else Promising.strategies_online\n",
    "\n",
    "        # add cycle strategy\n",
    "        if (all_colorings and graph.number_of_nodes() < cycles_all_max_vertices) or (not all_colorings and graph.number_of_nodes() < cycles_first_max_vertices):\n",
    "            strategies = itertools.chain(strategies, [None])\n",
    "\n",
    "        graph_id = graph_to_id(graph)\n",
    "        df_graph = df_seen.query(f\"graph == '{graph_id}'\")\n",
    "\n",
    "        for strategy in strategies:\n",
    "            # skip test that already run\n",
    "            if strategy is not None:\n",
    "                prev_record = df_graph.query(\n",
    "                    f\"relabel == '{strategy[0]}'\"\n",
    "                    + f\" and split == '{strategy[1]}'\"\n",
    "                    + f\" and merging == '{strategy[2]}'\"\n",
    "                    + f\" and subgraph_size == {strategy[3]}\"\n",
    "                    + f\" and use_smart_split == {use_smart_split}\"\n",
    "                    + f\" and used_monochromatic_classes == {use_monochromatic_classes}\"\n",
    "                )\n",
    "            else:\n",
    "                prev_record = df_graph.query(\n",
    "                    f\"relabel == 'none'\"\n",
    "                    + f\" and split == 'naive-cycles'\"\n",
    "                    + f\" and merging == 'naive-cycles'\"\n",
    "                    + f\" and subgraph_size == 0\"\n",
    "                    + f\" and use_smart_split == {use_smart_split}\"\n",
    "                    + f\" and used_monochromatic_classes == {use_monochromatic_classes}\"\n",
    "                )\n",
    "            if len(prev_record) > 0:\n",
    "                # ensureds graphs are recomputed if all_max_vertex_no is increased\n",
    "                if graph.number_of_nodes() > all_max_vertex_no or list(prev_record[\"nac_all_mean_time\"])[-1] > 0:\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                # print(strategy)\n",
    "                search_res = nac_benchmark_core(\n",
    "                    graph,\n",
    "                    rounds=rounds,\n",
    "                    first_only=not all_colorings,\n",
    "                    strategy=create_strategy(strategy, use_smart_split=use_smart_split) if strategy else (\"none\", \"cycles\"),\n",
    "                    use_monochromatic_classes=use_monochromatic_classes,\n",
    "                    time_limit=graph_timeout,\n",
    "                )\n",
    "\n",
    "                relabel, split, merge, subgraph_size = strategy if strategy else (\"none\", \"naive-cycles\", \"naive-cycles\", 0)\n",
    "                res = create_measurement_result(\n",
    "                    graph=graph,\n",
    "                    dataset_name=dataset_name,\n",
    "                    trianlge_classes=trianlge_classes,\n",
    "                    monochromatic_classes=monochromatic_classes,\n",
    "                    nac_first=search_res.first,\n",
    "                    nac_all=search_res.all,\n",
    "                    relabel_strategy=relabel,\n",
    "                    split_strategy=split,\n",
    "                    merge_strategy=merge,\n",
    "                    subgraph_size=subgraph_size,\n",
    "                    use_smart_split=use_smart_split,\n",
    "                    used_monochromatic_classes=use_monochromatic_classes,\n",
    "                )\n",
    "                results.append(res)\n",
    "                # print(res.nac_first_mean_time)\n",
    "            except Exception as e:\n",
    "                print(f\"Exception for strategy {strategy}: {e}\")\n",
    "                raise e\n",
    "\n",
    "    all_results.extend(results)\n",
    "    df = new_DataFrame(results)\n",
    "    update_stored_data([df], head_loaded=False)\n",
    "\n",
    "    df = new_DataFrame(all_results)\n",
    "    df = df.sort_values(by=[\"nac_all_mean_time\", \"nac_first_mean_time\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    df_test = measure_for_graph_class(\n",
    "        \"test\",\n",
    "        # [g for g in Graphs.laman if g.number_of_nodes() == 8][:8],\n",
    "        [g for g in Graphs.laman_nauty if g.number_of_nodes() < 12][:32],\n",
    "        # [g for g in Graphs.laman_deg_3_plus if g.number_of_nodes() == 8][:8],\n",
    "        # [g for g in Graphs.sparse_graphs if g.number_of_nodes() == 13][:8],\n",
    "        # Graphs.sparse_graphs,\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "        df_seen=df_benchmarks,\n",
    "        save_every=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laman Nauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_laman = measure_for_graph_class(\n",
    "        \"Laman\",\n",
    "        Graphs.laman_nauty,\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laman Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_laman_random = measure_for_graph_class(\n",
    "        \"Laman random\",\n",
    "        Graphs.laman_random,\n",
    "        all_max_vertex_no=18,\n",
    "        rounds=2,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laman deg 3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_laman_deg_3_plus = measure_for_graph_class(\n",
    "        \"Laman deg 3+\",\n",
    "        Graphs.laman_deg_3_plus,\n",
    "        # All with 36 strtegies, 3 rounds\n",
    "        #  8 - 1s/it\n",
    "        #  9 - 1s/it\n",
    "        # 10 - 2s/it\n",
    "        # 11 - 7s/it\n",
    "        # 12 - 15s/it -> ~20 mon. classes\n",
    "        # First coloring with 27 strategies, 3 rounds\n",
    "        # 15 - 5s/it\n",
    "        # 16 - 5s/it\n",
    "        # 17 - 90s/it\n",
    "        all_max_vertex_no=12,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No 3 nor 4 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    display(pd.Series([g.number_of_nodes() for g in Graphs.no_3_nor_4_cycles]).value_counts())\n",
    "    df_no_3_nor_4_cycles = measure_for_graph_class(\n",
    "        \"No 3 nor 4 cycles\",\n",
    "        Graphs.no_3_nor_4_cycles,\n",
    "        # 24 strategies\n",
    "        # 10 - 5 s/it\n",
    "        # 11 - 10 s/it\n",
    "        # 12 - 28 s/it\n",
    "        # 13 -\n",
    "        all_max_vertex_no=0,\n",
    "        rounds=2,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line graphs of no 3 nor 4 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    line_graphs = [\n",
    "        nx.convert_node_labels_to_integers(nx.line_graph(g))\n",
    "        for g in Graphs.no_3_nor_4_cycles\n",
    "        if max(deg for _, deg in g.degree) >= 3\n",
    "    ]\n",
    "\n",
    "    df_line_graphs_of_no_3_nor_4_cycles = measure_for_graph_class(\n",
    "        \"Line graph of no 3 nor 4 cycles\",\n",
    "        line_graphs,\n",
    "        all_max_vertex_no=13,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_sparse = measure_for_graph_class(\n",
    "        \"Sparse\",\n",
    "        Graphs.sparse_graphs,\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few coloring (formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_few_colorings = measure_for_graph_class(\n",
    "        \"few_colorings\",\n",
    "        dataset.generate_NAC_critical_graphs(30, 50, seed=None),\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "        df_seen=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    measure_for_graph_class(\n",
    "        \"few_colorings\",\n",
    "        Graphs.sparse_with_few_colorings,\n",
    "        all_max_vertex_no=0,\n",
    "        rounds=2,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globally rigid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    measure_for_graph_class(\n",
    "        \"globally_rigid\",\n",
    "        dataset.generate_globally_rigid_graphs(30, 50, seed=None),\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "        df_seen=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    measure_for_graph_class(\n",
    "        \"globally_rigid\",\n",
    "        dataset.generate_globally_rigid_graphs(10, 17, seed=None),\n",
    "        all_max_vertex_no=20,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "        df_seen=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_benchmarks = load_records()\n",
    "    globary_rigid_dataset = df_benchmarks.query(\"dataset == 'globally_rigid'\")['graph']\n",
    "    globary_rigid_dataset = list(graph_from_id(id) for id in globary_rigid_dataset.unique())\n",
    "\n",
    "    measure_for_graph_class(\n",
    "        \"globally_rigid\",\n",
    "        globary_rigid_dataset,\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    measure_for_graph_class(\n",
    "        \"globally_rigid\",\n",
    "        Graphs.globally_rigid,\n",
    "        all_max_vertex_no=17,\n",
    "        rounds=2,\n",
    "        graph_timeout=5,\n",
    "        cycles_first_max_vertices=100,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_benchmarks = load_records()\n",
    "    groupped = df_benchmarks.query(\"nac_any_finished == True and nac_first_coloring_no == 0 and triangle_components_no > 1\")[['graph', 'dataset']].drop_duplicates().groupby('dataset')\n",
    "\n",
    "    for dataset_name in groupped.groups.keys():\n",
    "        group = groupped.get_group(dataset_name)\n",
    "\n",
    "        print(dataset_name, len(group))\n",
    "        measure_for_graph_class(\n",
    "            dataset_name,\n",
    "            [graph_from_id(id) for id in group[\"graph\"]],\n",
    "            all_max_vertex_no=1,\n",
    "            rounds=1,\n",
    "            graph_timeout=40,\n",
    "            df_seen=df_benchmarks,\n",
    "            # This is the difference\n",
    "            use_monochromatic_classes=False,\n",
    "            use_smart_split=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No NAC coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS or True:\n",
    "    for name, data in {\n",
    "        \"no_NAC_coloring_generated_40\": Graphs.no_NAC_coloring_generated_40,\n",
    "        \"no_NAC_coloring_generated_50\": Graphs.no_NAC_coloring_generated_50,\n",
    "        \"no_NAC_coloring_generated_60\": Graphs.no_NAC_coloring_generated_60,\n",
    "        \"no_NAC_coloring_generated_70\": Graphs.no_NAC_coloring_generated_70,\n",
    "        \"no_NAC_coloring_generated_80\": Graphs.no_NAC_coloring_generated_80,\n",
    "        \"no_NAC_coloring_generated_90\": Graphs.no_NAC_coloring_generated_90,\n",
    "        \"no_NAC_coloring_generated_100\": Graphs.no_NAC_coloring_generated_100,\n",
    "        \"no_NAC_coloring_generated_110\": Graphs.no_NAC_coloring_generated_110,\n",
    "        # \"no_NAC_coloring_generated_120\": Graphs.no_NAC_coloring_generated_120,\n",
    "        # \"no_NAC_coloring_generated_130\": Graphs.no_NAC_coloring_generated_130,\n",
    "    }.items():\n",
    "        for smart_split in [False]:\n",
    "        # for smart_split in [False, True]:\n",
    "            print(name, smart_split)\n",
    "            measure_for_graph_class(\n",
    "                name,\n",
    "                data[:500],\n",
    "                all_max_vertex_no=0,\n",
    "                rounds=2,\n",
    "                graph_timeout=15,\n",
    "                cycles_first_max_vertices=0,\n",
    "                use_monochromatic_classes=False, # Most of the graphs have a single monochromatic class only -> it makes no sense for benchmarking\n",
    "                use_smart_split=smart_split,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather graphs with no NAC-coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_graph_class(\n",
    "    dataset_name: str,\n",
    "    name: str,\n",
    "):\n",
    "    df_benchmarks = load_records()\n",
    "    display(df_benchmarks[\"dataset\"].unique())\n",
    "    graphs = df_benchmarks.query(f\"nac_any_finished == True and dataset == '{dataset_name}'\")['graph'].drop_duplicates()\n",
    "    output_dir = f\"graphs_store/random\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    path = os.path.join(output_dir, f\"{name}.g6\")\n",
    "    lines = 0\n",
    "    with open(path, \"wb\") as f:\n",
    "        for graph in graphs:\n",
    "            lines += 1\n",
    "            graph = graph_from_id(graph)\n",
    "            # graph = nx.graph6.from_graph6_bytes(graph)\n",
    "            graph = nx.graph6.to_graph6_bytes(graph, header=False)\n",
    "            f.write(graph)\n",
    "    print(lines)\n",
    "\n",
    "def export_sparse_graphs_with_few_colorings():\n",
    "    graphs = [g for g, _ in zip(dataset.generate_NAC_critical_graphs(30, 60, seed=None), range(2000))]\n",
    "    output_dir = f\"graphs_store/random\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    name = \"test\"\n",
    "    path = os.path.join(output_dir, f\"{name}.g6\")\n",
    "    lines = 0\n",
    "    with open(path, \"wb\") as f:\n",
    "        for graph in graphs:\n",
    "            lines += 1\n",
    "            # graph = graph_from_id(graph)\n",
    "            # graph = nx.graph6.from_graph6_bytes(graph)\n",
    "            graph = nx.graph6.to_graph6_bytes(graph, header=False)\n",
    "            f.write(graph)\n",
    "    print(lines)\n",
    "\n",
    "def export_no_NAC_coloring():\n",
    "    df_benchmarks = load_records()\n",
    "    df = df_benchmarks.query(\"nac_any_finished == True and nac_first_coloring_no == 0 and triangle_components_no > 1\")\n",
    "    print(f\"Export from groups: {df[\"dataset\"].unique()}\")\n",
    "    graphs = df['graph'].drop_duplicates()\n",
    "\n",
    "    output_dir = f\"graphs_store/extracted\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    name = \"no_nac_coloring\"\n",
    "    path = os.path.join(output_dir, f\"{name}.g6\")\n",
    "    lines = 0\n",
    "    with open(path, \"wb\") as f:\n",
    "        for graph in graphs:\n",
    "            lines += 1\n",
    "            graph = graph_from_id(graph)\n",
    "            # graph = nx.graph6.from_graph6_bytes(graph)\n",
    "            graph = nx.graph6.to_graph6_bytes(graph, header=False)\n",
    "            f.write(graph)\n",
    "    print(lines)\n",
    "\n",
    "# export_no_NAC_coloring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics\n",
    "\n",
    "Base graphs show the time required to find\n",
    "a first/all NAC coloring based on vertex no./monochromatic classes no.\n",
    "First graphs are separated for each class of graphs and\n",
    "in the end for all the classes combined.\n",
    "Graphs are drawn for each strategy cathegory to compare them easily.\n",
    "Graphs show mean, median and 1st quartil values of running times to lower bias.\n",
    "\n",
    "Second group of graphs shows our contribution of decresing\n",
    "the number of `is_NAC_coloring` checks called compared to\n",
    "the naive approach without or with triangle/monochromatic classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytics = load_records()\n",
    "\n",
    "print(\n",
    "    \"Graphs with no NAC-coloring and more monochromatic classes\",\n",
    "    df_analytics.query(\"nac_any_finished == True and nac_first_coloring_no == 0 and monochromatic_classes_no > 1\")['graph'].nunique(),\n",
    ")\n",
    "\n",
    "\n",
    "df_analytics = df_analytics.query(\"dataset != 'test'\")\n",
    "df_analytics = df_analytics.query(\"split != 'kernighan_lin' and split != 'cuts'\")\n",
    "df_analytics = df_analytics.query(\"merging != 'log' and merging != 'score' and merging != 'promising_cycles'\")\n",
    "\n",
    "df_analytics = df_analytics.assign(split_merging=lambda x: (x[\"split\"] + \" & \" + x[\"merging\"]).str.replace(\"naive-cycles & naive-cycles\", \"naive cycles\"))\n",
    "df_analytics = df_analytics.assign(split_merging_smart=lambda x: x[\"split_merging\"] + \" & \" + x[\"use_smart_split\"].astype(str))\n",
    "\n",
    "graphs_where_all_strategies_finished = df_analytics[[\"graph\", \"nac_any_finished\"]].groupby(\"graph\").all()\n",
    "print(f\"{graphs_where_all_strategies_finished.index.nunique()}/{df_analytics[\"graph\"].nunique()} graphs finished on all strategies.\")\n",
    "df_analytics = df_analytics.query(\"nac_any_finished == True\")\n",
    "\n",
    "df_analytics_no_nac = df_analytics.query(\"nac_first_coloring_no == 0 and triangle_components_no > 1 and used_monochromatic_classes == False\")\n",
    "df_analytics = df_analytics.query(\"monochromatic_classes_no > 1\")\n",
    "\n",
    "# display(df_analytics.info())\n",
    "print(\"Records:\", df_analytics.shape[0], \"graphs:\", df_analytics[\"graph\"].nunique())\n",
    "display(df_analytics.columns)\n",
    "display(list(df_analytics[\"dataset\"].unique()))\n",
    "display(list(df_analytics[\"relabel\"].unique()))\n",
    "display(list(df_analytics_no_nac[\"split\"].unique()))\n",
    "display(list(df_analytics[\"merging\"].unique()))\n",
    "\n",
    "# make sure this spelling mistatake is forever fixed\n",
    "assert \"globaly_rigid\" not in df_analytics[\"dataset\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _group_and_plot(\n",
    "    df: pd.DataFrame,\n",
    "    axs: List[plt.Axes],\n",
    "    x_column: Literal[\"vertex_no\", \"monochromatic_classes_no\"],\n",
    "    based_on: Literal[\"relabel\", \"split\", \"merging\"],\n",
    "    value_columns: List[Literal[\"nac_first_mean_time\", \"nac_all_mean_time\"]],\n",
    "):\n",
    "    aggregations = [\"mean\", \"median\", \"3rd quartile\"]\n",
    "    df = df.loc[:, [x_column, based_on, *value_columns]]\n",
    "    groupped = df.groupby([x_column, based_on])\n",
    "\n",
    "    for ax, aggregation in zip(axs, aggregations):\n",
    "        match aggregation:\n",
    "            case \"mean\":\n",
    "                aggregated = groupped.mean()\n",
    "            case \"median\":\n",
    "                aggregated = groupped.median()\n",
    "            case \"3rd quartile\":\n",
    "                aggregated = groupped.quantile(.75)\n",
    "\n",
    "        aggregated = aggregated.reorder_levels([based_on, x_column], axis=0)\n",
    "\n",
    "        for name in aggregated.index.get_level_values(based_on).unique():\n",
    "            data = aggregated.loc[name]\n",
    "            for value_column in value_columns:\n",
    "                title = \",\".join([name, value_column]) if len(value_columns) > 1 else name\n",
    "                ax.plot(data.index, data[value_column], label=title)\n",
    "\n",
    "        ax.set_title(f\"{x_column} {based_on} ({aggregation})\")\n",
    "        if \"time\" in value_columns[0]:\n",
    "            ax.set_ylabel(\"Time [ms]\")\n",
    "        if \"check\" in value_columns[0]:\n",
    "            ax.set_ylabel(\"#Check calls\")\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.legend()\n",
    "\n",
    "def plot_frame(\n",
    "    title: str,\n",
    "    df: pd.DataFrame,\n",
    "    ops_value_columns_sets = [\n",
    "        [ \"nac_first_mean_time\", ],\n",
    "        [ \"nac_first_check_cycle_mask\", ],\n",
    "        [ \"nac_all_mean_time\", ],\n",
    "        [ \"nac_all_check_cycle_mask\", ],\n",
    "    ],\n",
    "    ops_x_column = [\"vertex_no\", \"monochromatic_classes_no\",],\n",
    "    ops_based_on = [\n",
    "        # \"relabel\",\n",
    "        # \"split\",\n",
    "        # \"merging\",\n",
    "        \"split_merging\",\n",
    "        \"use_smart_split\",\n",
    "        \"subgraph_size\",\n",
    "    ],\n",
    "    ops_aggregation = [\"mean\", \"median\", \"3rd quartile\",]\n",
    ") -> List[Figure]:\n",
    "    print(f\"Plotting {df.shape[0]} records...\")\n",
    "    figs = []\n",
    "\n",
    "    for value_columns in ops_value_columns_sets:\n",
    "        local_df = df[(df[value_columns] != 0).all(axis=1)]\n",
    "        if local_df.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        nrows = len(ops_x_column) * len(ops_based_on)\n",
    "        ncols = len(ops_aggregation)\n",
    "        fig = figure(nrows * ncols, (20, 6 * nrows), layout='constrained')\n",
    "        fig.suptitle(f\"{title} - time of NAC coloring search ({value_columns})\", fontsize=20)\n",
    "        figs.append(fig)\n",
    "\n",
    "        row = 0\n",
    "        for x_column in ops_x_column:\n",
    "            for based_on in ops_based_on:\n",
    "                axs = [\n",
    "                    fig.add_subplot(nrows, ncols, i+ncols*row+1)\n",
    "                    for i in range(3)]\n",
    "                _group_and_plot(local_df, axs, x_column, based_on, value_columns)\n",
    "                row += 1\n",
    "    return figs\n",
    "\n",
    "# [display(fig) for fig in plot_frame(\"Laman\", df_analytics.query(\"dataset == 'laman'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False:\n",
    "    [display(fig) for fig in plot_frame(\"Laman\", df_analytics.query(\"dataset == 'laman'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    [display(fig) for fig in plot_frame(\"Laman random\", df_analytics.query(\"dataset == 'laman_random'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False:\n",
    "    [display(fig) for fig in plot_frame(\"Laman deg 3+\", df_analytics.query(\"dataset == 'laman_deg_3+'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    [display(fig) for fig in plot_frame(\"No 3 nor 4 cycles\", df_analytics.query(\"dataset == 'no_3_nor_4_cycles'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False:\n",
    "    [display(fig) for fig in plot_frame(\"Line graphs of no 3 nor 4 cycles\", df_analytics.query(\"dataset == 'line_graph_of_no_3_nor_4_cycles'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False:\n",
    "    [display(fig) for fig in plot_frame(\"Sparse\", df_analytics.query(\"dataset == 'sparse'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False:\n",
    "    [display(fig) for fig in plot_frame(\"Few colorings - None\", df_analytics.query(\"dataset == 'few_colorings'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    [display(fig) for fig in plot_frame(\"Globally rigid\", df_analytics.query(\"dataset == 'globally_rigid'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    [display(fig) for fig in plot_frame(\"No NAC-coloring gathered, ▵-components\", df_analytics_no_nac, ops_x_column = [\"vertex_no\", \"triangle_components_no\",],)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_analytics_no_nac[\"merging\"].unique())\n",
    "display(df_analytics_no_nac[\"split\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS or True:\n",
    "    base = df_analytics_no_nac.query(\"merging!='naive-cycles' and merging!='min_max' and merging!='sorted_bits' and split!='neighbors_iterative' and split!='beam_neighbors'\")\n",
    "    base_40 = base.query(\"dataset == 'no_nac_coloring_generated_40'\")\n",
    "    base_50 = base.query(\"dataset == 'no_nac_coloring_generated_50'\")\n",
    "    base_60 = base.query(\"dataset == 'no_nac_coloring_generated_60'\")\n",
    "    base_70 = base.query(\"dataset == 'no_nac_coloring_generated_70'\")\n",
    "    base_80 = base.query(\"dataset == 'no_nac_coloring_generated_80'\")\n",
    "    base_90 = base.query(\"dataset == 'no_nac_coloring_generated_90'\")\n",
    "    base_100 = base.query(\"dataset == 'no_nac_coloring_generated_100'\")\n",
    "    base_110 = base.query(\"dataset == 'no_nac_coloring_generated_110'\")\n",
    "    df = pd.concat([base_40, base_50, base_60, base_70, base_80, base_90, base_100, base_110], ignore_index=True)\n",
    "    [display(fig) for fig in plot_frame(\n",
    "        \"No NAC-coloring generated 40, ▵-components\",\n",
    "        # and merging=='shared_vertices'\n",
    "        # and split=='cycles_match_chunks'\n",
    "        df,#.query(\"\"),\n",
    "        ops_x_column = [\"vertex_no\", \"triangle_components_no\",],\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_is_NAC_coloring_calls_groups(\n",
    "    title: str,\n",
    "    df: pd.DataFrame,\n",
    "    ax: plt.Axes,\n",
    "    x_column: Literal[\"vertex_no\", \"monochromatic_classes_no\"],\n",
    "    value_columns: List[Literal[\"nac_first_mean_time\", \"nac_all_mean_time\"]],\n",
    "    aggregation: Literal[\"mean\", \"median\", \"3rd quartile\"]\n",
    "):\n",
    "    df = df.loc[:, [x_column, *value_columns]]\n",
    "    groupped = df.groupby([x_column])\n",
    "    match aggregation:\n",
    "        case \"mean\":\n",
    "            aggregated = groupped.mean()\n",
    "        case \"median\":\n",
    "            aggregated = groupped.median()\n",
    "        case \"3rd quartile\":\n",
    "            aggregated = groupped.quantile(.75)\n",
    "\n",
    "    # display(aggregated)\n",
    "    aggregated.plot(ax=ax)\n",
    "    ax.set_title(f\"{title} {x_column} ({aggregation})\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.legend()\n",
    "\n",
    "def plot_is_NAC_coloring_calls(\n",
    "    df: pd.DataFrame,\n",
    ") -> List[Figure]:\n",
    "    figs = []\n",
    "\n",
    "    df = df.query(\"nac_all_coloring_no != 0\").copy()\n",
    "    print(f\"Plotting {df.shape[0]} records...\")\n",
    "\n",
    "    related_columns = [\"vertex_no\", \"edge_no\", \"triangle_components_no\", \"monochromatic_classes_no\", \"nac_all_coloring_no\", \"nac_all_check_is_NAC\", \"nac_all_check_cycle_mask\"]\n",
    "    df = df.loc[:, related_columns]\n",
    "    # this does not help our algorithm to stand out, but the graphs can be drawn more easily\n",
    "\n",
    "    df[\"exp_edge_no\"]               = 2**(df[\"edge_no\"]-1)\n",
    "    df[\"exp_triangle_component_no\"] = 2**(df[\"triangle_components_no\"]-1)\n",
    "    df[\"exp_monochromatic_class_no\"] = 2**(df[\"monochromatic_classes_no\"]-1)\n",
    "\n",
    "    df[\"scaled_edge_no\"]                  = df[\"edge_no\"]                  /df[\"nac_all_coloring_no\"]\n",
    "    df[\"scaled_triangle_component_no\"]    = df[\"triangle_components_no\"]   /df[\"nac_all_coloring_no\"]\n",
    "    df[\"scaled_monochromatic_class_no\"]    = df[\"monochromatic_classes_no\"] /df[\"nac_all_coloring_no\"]\n",
    "    df[\"scaled_nac_all_check_cycle_mask\"] = df[\"nac_all_check_cycle_mask\"] /df[\"nac_all_coloring_no\"]\n",
    "\n",
    "    df[\"inv_edge_no\"]                  = df[\"nac_all_coloring_no\"] / df[\"edge_no\"]\n",
    "    df[\"inv_triangle_component_no\"]    = df[\"nac_all_coloring_no\"] / df[\"triangle_components_no\"]\n",
    "    df[\"inv_monochromatic_class_no\"]    = df[\"nac_all_coloring_no\"] / df[\"monochromatic_classes_no\"]\n",
    "    df[\"inv_nac_all_check_is_NAC\"]     = df[\"nac_all_coloring_no\"] / df[\"nac_all_check_is_NAC\"]\n",
    "    df[\"inv_nac_all_check_cycle_mask\"] = df[\"nac_all_coloring_no\"] / df[\"nac_all_check_cycle_mask\"]\n",
    "\n",
    "    df[\"new_edge_no\"]                  = df[\"edge_no\"]                  /df[\"exp_monochromatic_class_no\"]\n",
    "    df[\"new_triangle_component_no\"]    = df[\"triangle_components_no\"]   /df[\"exp_monochromatic_class_no\"]\n",
    "    df[\"new_monochromatic_class_no\"]    = df[\"monochromatic_classes_no\"] /df[\"exp_monochromatic_class_no\"]\n",
    "    df[\"new_nac_all_check_cycle_mask\"] = df[\"nac_all_check_cycle_mask\"] /df[\"exp_monochromatic_class_no\"]\n",
    "\n",
    "    ops_x_column = [\"vertex_no\", \"monochromatic_classes_no\",]\n",
    "    ops_value_groups = [\n",
    "        [\"exp_edge_no\",    \"exp_triangle_component_no\",    \"exp_monochromatic_class_no\",    \"nac_all_check_cycle_mask\",        \"nac_all_check_is_NAC\",     \"nac_all_coloring_no\"],\n",
    "        # [\"scaled_edge_no\", \"scaled_triangle_component_no\", \"scaled_monochromatic_class_no\", \"scaled_nac_all_check_cycle_mask\"],\n",
    "        [\"inv_edge_no\",    \"inv_triangle_component_no\",    \"inv_monochromatic_class_no\",    \"inv_nac_all_check_cycle_mask\",    \"inv_nac_all_check_is_NAC\", ],\n",
    "        # [\"new_edge_no\",    \"new_triangle_component_no\",    \"new_monochromatic_class_no\",    \"new_nac_all_check_cycle_mask\" ],\n",
    "    ]\n",
    "    ops_aggregation = [\"mean\", \"median\", \"3rd quartile\",]\n",
    "\n",
    "    nrows = len(ops_x_column) * len(ops_value_groups)\n",
    "    ncols = len(ops_aggregation)\n",
    "    fig = figure(nrows * ncols, (20, 4 * nrows), layout='constrained')\n",
    "    fig.suptitle(f\"Reduction of is_NAC_coloring checks against the naive algorithm\", fontsize=20)\n",
    "    figs.append(fig)\n",
    "\n",
    "    row = 0\n",
    "    for x_column in ops_x_column:\n",
    "        for title, value_columns in zip(\n",
    "            [\n",
    "                \"Base: #is_NAC_coloring\",\n",
    "                \"Scaled: #is_NAC_coloring() calls/#NAC(G)\",\n",
    "                \"Inverse: #NAC(G)/#is_NAC_coloring() calls\",\n",
    "                \"Count: metric / monochromatic classes no.\",\n",
    "            ],\n",
    "            ops_value_groups,\n",
    "        ):\n",
    "            axs = [\n",
    "                fig.add_subplot(nrows, ncols, i+ncols*row+1)\n",
    "                for i in range(3)]\n",
    "            for ax, aggregation in zip(axs,ops_aggregation):\n",
    "                _plot_is_NAC_coloring_calls_groups(title, df, ax, x_column, value_columns, aggregation)\n",
    "            row += 1\n",
    "\n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    [display(fig) for fig in plot_is_NAC_coloring_calls(df_analytics.query(\"split != 'naive-cycles'\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisson with naive approach\n",
    "\n",
    "In this section of benchmarks we run our algorithm on all the Laman graphs of specified size.\n",
    "The goal is to show the performance improvement over the previous SOTA - naive approach.\n",
    "For clarity and simplicity we use only a single strategy - `neighbors_degree` with `linear` merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_colorings_on_all_graphs(\n",
    "    dataset_name: str,\n",
    "    graphs: Callable[[], Iterable[nx.Graph]],\n",
    "    vertex_no: int,\n",
    "    algorithm: str = \"subgraphs-linear-neighbors_degree-4-smart\",\n",
    "    DIR: str = os.path.join(\"benchmarks\", \"results\", \"iteration\"),\n",
    "    time_log: str | None =  None\n",
    "):\n",
    "    os.makedirs(DIR, exist_ok=True)\n",
    "    time_log = time_log or os.path.join(DIR, \"log.csv\")\n",
    "\n",
    "    stats = defaultdict(int)\n",
    "    rand = random.Random(42)\n",
    "\n",
    "    # print(f\"Running {algorithm} on {len(graphs)} graphs with {vertex_no} vertices\")\n",
    "    print(f\"Running {algorithm} on graphs with {vertex_no} vertices\")\n",
    "    graphs = graphs()\n",
    "    start = time.time()\n",
    "    for graph in tqdm(graphs):\n",
    "        iterable = nac.NAC_colorings(\n",
    "            graph,\n",
    "            algorithm=algorithm,\n",
    "            relabel_strategy=\"none\",\n",
    "            use_decompositions=False,\n",
    "            use_has_coloring_check=False,\n",
    "            seed=rand.randint(0, 2**32 - 1),\n",
    "        )\n",
    "        counter = itertools.count()\n",
    "        deque(zip(iterable, counter), maxlen=0)\n",
    "        coloring_no = next(counter) // 2\n",
    "        stats[coloring_no] += 1\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"The operation took {int(1_000_000*(end-start))}s\")\n",
    "    with open(time_log, \"a\") as f:\n",
    "        print(f\"{vertex_no},{algorithm},{int(1000*(end-start))}\", file=f, flush=True)\n",
    "\n",
    "    data = np.array(list(stats.items()))\n",
    "    df = pd.DataFrame(data, columns=[\"coloring_cnt\", \"graph_cnt\"])\n",
    "    df.sort_values(by=\"coloring_cnt\", inplace=True)\n",
    "    df[\"graph_cnt\"]\n",
    "    print(\n",
    "        f\"Most colorings: {tuple(df.iloc[-1])}, Most common: {tuple(df.loc[df[\"graph_cnt\"].idxmax()])} (coloring_cnt, graph_cnt)\"\n",
    "    )\n",
    "    # print(df.tail(n=50))\n",
    "\n",
    "    df.to_csv(os.path.join(DIR, f\"{dataset_name}_{vertex_no}_{algorithm}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = list(dataset.load_laman_degree_3_plus_all(vertex_no))\n",
    "\n",
    "if False:\n",
    "    for n in list(range(7, 12 + 1)):\n",
    "        RUN_AS_BENCHMARK_NOT_JUST_FOR_THE_STATS = False\n",
    "        if RUN_AS_BENCHMARK_NOT_JUST_FOR_THE_STATS:\n",
    "            # TODO improve so the dataset is not loaded every time\n",
    "            graphs = lambda: list(dataset.load_laman_all(n))\n",
    "        else:\n",
    "            graphs = lambda: dataset.load_laman_all(n)\n",
    "\n",
    "        find_colorings_on_all_graphs(\"laman\", graphs, n,)\n",
    "        find_colorings_on_all_graphs(\"laman\", graphs, n, \"naive\") if n <= 10 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for big graph with more monochromatic components but no NAC coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_large_graph_no_NAC_coloring(\n",
    "    nl: int,\n",
    "    nh: int,\n",
    ") -> None:\n",
    "    rand = random.Random()\n",
    "\n",
    "    while True:\n",
    "        n = rand.randint(nl, nh)\n",
    "        m = 2*n-2 + rand.randint(0, 8*n)\n",
    "        graph = nx.gnm_random_graph(n, m, seed=rand.randint(0, 2**30))\n",
    "        if not nx.is_connected(graph):\n",
    "            continue\n",
    "        classes_no = nac.find_monochromatic_classes(graph)[1]\n",
    "        if not len(classes_no) > 10:\n",
    "            continue\n",
    "        coloring = next(nac.NAC_colorings(\n",
    "            graph,\n",
    "            algorithm=create_strategy((\"\", \"neighbors_degree\", \"shared_vertices\", 6))[1],\n",
    "        ), None)\n",
    "        if coloring is not None:\n",
    "            continue\n",
    "        print(f\"{classes_no}: {nx.graph6.to_graph6_bytes(header=False).strip()}\")\n",
    "if SEARCH:\n",
    "    search_large_graph_no_NAC_coloring(40, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SEARCH:\n",
    "    df_benchmarks.query(\"dataset == 'sparse' and nac_first_coloring_no == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_monter_3_trism_with_edge(prism_no: int) -> nx.Graph:\n",
    "    graph = nac.util.NiceGraph()\n",
    "    graph.add_edges_from([\n",
    "        ('A', 'B'), ('B', 'C'), ('C', 'A'),\n",
    "        ('A', 'D'), ('B', 'D'),\n",
    "        ('D', 'E'), ('B', 'E'),\n",
    "    ])\n",
    "    for i in range(1, prism_no+1):\n",
    "        graph.add_edges_from([\n",
    "            (f'A{i}', f'B{i}'), (f'B{i}', f'C{i}'), (f'C{i}', f'A{i}'),\n",
    "            ('A', f'A{i}'), ('B', f'B{i}'), ('C', f'C{i}'),\n",
    "            ('A', f'E{i}'), # the problems causing edge\n",
    "        ])\n",
    "\n",
    "    graph = nx.convert_node_labels_to_integers(graph)\n",
    "    return graph\n",
    "for i in range(5):\n",
    "    graph = build_monter_3_trism_with_edge(i)\n",
    "    print(len(nac.find_monochromatic_classes(graph=graph, class_type=MonochromaticClassType.MONOCHROMATIC)[1]))\n",
    "    print(next(iter(nac.NAC_colorings(graph)), None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
