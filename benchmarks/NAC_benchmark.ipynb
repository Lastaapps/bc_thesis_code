{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAC coloring search\n",
    "\n",
    "In this notebook we provide utils to run benchmarks and experiment with our code.\n",
    "\n",
    "In the first section we start with utility functions, in the second part we load/generate benchmark data. After we run individual benchmarks on selected graph classes with selected algorithms. The algorithms are described in that section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using VScode, add this option to your `.vscode/settings.json` file.\n",
    "```json\n",
    "{\n",
    "    \"jupyter.notebookFileRoot\": \"${workspaceFolder}\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict, deque\n",
    "import random\n",
    "import importlib\n",
    "from random import Random\n",
    "from enum import Enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline as backend_inline\n",
    "from matplotlib.backends import backend_agg\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import signal\n",
    "import itertools\n",
    "import base64\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nac as nac\n",
    "from nac import MonochromaticClassType\n",
    "\n",
    "import benchmarks\n",
    "from benchmarks import dataset\n",
    "from benchmarks import generators\n",
    "import benchmarks.notebook_utils\n",
    "from benchmarks.notebook_utils import *\n",
    "\n",
    "seed=42\n",
    "TEST=False\n",
    "BENCHMARKS=False\n",
    "ANALYTICS=True\n",
    "SEARCH=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(nac)\n",
    "importlib.reload(benchmarks.dataset)\n",
    "importlib.reload(benchmarks.generators)\n",
    "importlib.reload(benchmarks)\n",
    "importlib.reload(benchmarks.notebook_utils)\n",
    "\n",
    "_BENCH_FILE_START_V2 = \"bench_res_v2\"\n",
    "_BENCH_FILE_START_V3 = \"bench_res_v3\"\n",
    "_BENCH_FILE_START_V4 = \"bench_res_v4\"\n",
    "\n",
    "OUTPUT_DIR = os.path.join(\"benchmarks\", \"runs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "benchmarks.notebook_utils.OUTPUT_DIR = OUTPUT_DIR\n",
    "benchmarks.notebook_utils.OUTPUT_BENCH_FILE_START = _BENCH_FILE_START_V4\n",
    "benchmarks.notebook_utils.OUTPUT_VERBOSE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading locally stored graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graphs:\n",
    "    \"\"\"\n",
    "    Randomly generated laman graphs of various sizes\n",
    "    \"\"\"\n",
    "    laman_random = LazyList(lambda: dataset.load_laman_random_graphs())\n",
    "    \"\"\"\n",
    "    Graphs with no 3 nor 4 cycles up to 42 vertices\n",
    "    \"\"\"\n",
    "    no_3_nor_4_cycles = LazyList(lambda: dataset.load_no_3_nor_4_cycle_graphs())\n",
    "    \"\"\"\n",
    "    Graphs generated according to yet unpublished formula that guaranties that these graphs should either have none or small number of NAC-colorings\n",
    "    \"\"\"\n",
    "    sparse_with_few_colorings = LazyList(lambda: dataset.load_sparse_with_few_colorings_graphs())\n",
    "    \"\"\"\n",
    "    Globally rigid graphs\n",
    "    \"\"\"\n",
    "    globally_rigid = LazyList(lambda: dataset.load_globally_rigid_graphs())\n",
    "    \"\"\"\n",
    "    Graphs gathered from other cathegories that have no NAC-coloring and more than one triangle-connected component\n",
    "    \"\"\"\n",
    "    no_NAC_coloring_gathered = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_gathered())\n",
    "    \"\"\"\n",
    "    Random (globally rigid) graphs that have no NAC-coloring and more than 2*sqrt(n) triangle-connected components\n",
    "    \"\"\"\n",
    "    no_NAC_coloring_generated_40 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(40))\n",
    "    no_NAC_coloring_generated_50 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(50))\n",
    "    no_NAC_coloring_generated_60 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(60))\n",
    "    no_NAC_coloring_generated_70 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(70))\n",
    "    no_NAC_coloring_generated_80 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(80))\n",
    "    no_NAC_coloring_generated_90 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(90))\n",
    "    no_NAC_coloring_generated_100 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(100))\n",
    "    no_NAC_coloring_generated_110 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(110))\n",
    "    no_NAC_coloring_generated_120 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(120))\n",
    "    no_NAC_coloring_generated_130 = LazyList(lambda: dataset.load_no_NAC_coloring_graphs_generated(130))\n",
    "\n",
    "    laman_nauty = LazyList(lambda: dataset.load_laman_graphs())\n",
    "    laman_deg_3_plus = LazyList(lambda: dataset.load_laman_degree_3_plus())\n",
    "    sparse_graphs = LazyList(lambda: (\n",
    "        dataset.generate_sparse_graphs(30, 40, count=64) +\n",
    "        dataset.generate_sparse_graphs(40, 50, count=32) +\n",
    "        dataset.generate_sparse_graphs(50, 60, count=16) +\n",
    "        dataset.generate_sparse_graphs(60, 70, count=8)\n",
    "    ))\n",
    "\n",
    "    \"\"\"\n",
    "    Loads all the Laman graphs of the given size, pregenerated files allow the range of [5, 11]\n",
    "    In case you want to use it in benchmarks, list all the graphs first.\n",
    "    \"\"\"\n",
    "    def load_all_laman(vertex_no: int) -> Iterator[nx.Graph]:\n",
    "        return dataset.load_laman_all(vertices_no=vertex_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell bellow generates random laman graphs and stores them as `./benchmarks/graph-store/laman-random/laman_{n}.g6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = defaultdict(list)\n",
    "# for graph in Graphs.globally_rigid:\n",
    "#     mapping[graph.number_of_nodes()].append(graph)\n",
    "# display([(k, len(v)) for k, v in sorted(mapping.items())])\n",
    "# for k, v in sorted(mapping.items()):\n",
    "#     path = os.path.join(dataset.RANDOM_DIR, f\"globally_rigid\")\n",
    "#     os.makedirs(path, exist_ok=True)\n",
    "#     name = f\"globally_rigid_{k}.g6\"\n",
    "#     path = os.path.join(path, name)\n",
    "#     generators._write_graphs_to_file(path, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and loading benchmark results\n",
    "\n",
    "Each row represents performance of a graph with a given strategy.\n",
    "The difference between the first and all variant is that\n",
    "in the all variants we search for all NAC-colorings,\n",
    "but in the first variant we search only.\n",
    "\n",
    "The export CSV columns are:\n",
    "- `timestamp` - date time of the test in UTC\n",
    "- `graph` - base64 encoded bytes of graph6 encoded graph\n",
    "- `dataset` - class of the graph, `minimally_ridig_random`, `no_3_nor_4_cycles`, `globally_rigid`, ...\n",
    "- `vertex_no` - the number of vertices of the graph\n",
    "- `edge_no` - the number of edges of the graph\n",
    "- `triangle_components_no` - the number of triangle components of the graph\n",
    "- `monochromatic_classes_no` - the number of monochromatic classes of the graph\n",
    "- `relabel` - relabel strategy (relabels vertices before the main algorithm is run, here we have only `none` or `random`)\n",
    "- `split` - splitting strategy\n",
    "- `merge` - merging strategy\n",
    "- `subgraph_size` - the target initial size of subgraphs in monochromatic components\n",
    "- `used_monochromatic_classes` - if monochromatic classes were used to run the test, `False` means triangle components were used\n",
    "- `nac_any_finished` - if any of the tests finished in time\n",
    "- `nac_{first|all}_coloring_no` - the number of NAC-colorings of the graph, for the first variant limited to 1\n",
    "- `nac_{first|all}_mean_time` - the time required to find first/all NAC-colorings in milliseconds\n",
    "- `nac_{first|all}_rounds` - the number of rounds used to run the benchmarks\n",
    "- `nac_{first|all}_check_cycle_mask` - the number of cycle mask checks performed\n",
    "- `nac_{first|all}_check_is_NAC` - the number of `IsNACColorng` checks performed\n",
    "- `nac_{first|all}_merge` - the number of merges performed\n",
    "- `nac_{first|all}_merge_no_common_vertex` - the number of merges with no common vertex (these are simple to compute, but produce large no of colorings slowing down the algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Promising:\n",
    "    RELABELING = [\n",
    "        \"none\",\n",
    "        # \"random\",\n",
    "        # \"bfs\",\n",
    "    ]\n",
    "    SPLITTING = [\n",
    "        \"none\",\n",
    "        # \"cycles_match_chunks\",\n",
    "        \"neighbors\",\n",
    "        # \"neighbors_degree\",\n",
    "        # \"beam_neighbors\",\n",
    "    ]\n",
    "    MERGING_OFFLINE = [\n",
    "        \"linear\",\n",
    "        # \"score\",\n",
    "        # \"shared_vertices\",\n",
    "        # \"sorted_size\",\n",
    "    ]\n",
    "    MERGING_ONLINE = [\n",
    "        \"linear\",\n",
    "        # \"shared_vertices\",\n",
    "        # \"sorted_size\",\n",
    "    ]\n",
    "    SIZES = [4, 5] # [4, 5, 6, 7]\n",
    "\n",
    "    strategies_offline = list(itertools.product(\n",
    "        RELABELING, SPLITTING, MERGING_OFFLINE, SIZES,\n",
    "    ))\n",
    "    strategies_online = list(itertools.product(\n",
    "        RELABELING, SPLITTING, MERGING_ONLINE, SIZES,\n",
    "    ))\n",
    "print(f\"Offline strategies: {len(Promising.strategies_offline)}\")\n",
    "print(f\"Online strategies:  {len(Promising.strategies_online)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File storage management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_DataFrame(data: List[MeasurementResult] = []) -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        [x.to_list() for x in data],\n",
    "        columns=COLUMNS,\n",
    "    )\n",
    "\n",
    "def update_stored_data(dfs: List[pd.DataFrame] = [], head_loaded: bool = True) -> pd.DataFrame:\n",
    "    df = load_records()\n",
    "    if head_loaded:\n",
    "        display(df)\n",
    "    if len(dfs) != 0:\n",
    "        df = pd.concat((df, pd.concat(dfs)))\n",
    "    df = df.drop_duplicates(\n",
    "        subset=[\"graph\", \"dataset\", \"split\", \"relabel\", \"merging\", \"subgraph_size\", \"use_smart_split\", \"used_monochromatic_classes\"],\n",
    "        keep='last',\n",
    "    )\n",
    "    store_results(df)\n",
    "    return df\n",
    "\n",
    "def migrate_v2_to_v3(dir = OUTPUT_DIR) -> pd.DataFrame:\n",
    "    file_name_v2 = find_latest_record_file(_BENCH_FILE_START_V2, dir)\n",
    "    path = os.path.join(dir, file_name_v2)\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"use_smart_split\"] = True\n",
    "    df[\"used_monochromatic_classes\"] = True\n",
    "    df.loc[df[\"dataset\"] == 'laman_random_no_smart_split', \"use_smart_split\"] = False\n",
    "    df.loc[df[\"dataset\"] == 'laman_random_no_smart_split', \"dataset\"] = 'laman_random'\n",
    "    df = df[COLUMNS]\n",
    "    store_results(df, None, dir)\n",
    "\n",
    "def migrate_v3_to_v4(dir = OUTPUT_DIR) -> pd.DataFrame:\n",
    "    file_name_v3 = find_latest_record_file(_BENCH_FILE_START_V3, dir)\n",
    "    path = os.path.join(dir, file_name_v3)\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"timestamp\"] = datetime.datetime(1970, 1, 1)\n",
    "    df[\"nac_first_merge\"] = -1\n",
    "    df[\"nac_first_merge_no_common_vertex\"] = -1\n",
    "    df[\"nac_all_merge\"] = -1\n",
    "    df[\"nac_all_merge_no_common_vertex\"] = -1\n",
    "    df = df[COLUMNS]\n",
    "    store_results(df, None, dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running and recording benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_strategy(param: Tuple[str, str, str, int], use_smart_split: bool) -> Tuple[str, str]:\n",
    "    relabel, split, merge, subgraph = param\n",
    "    algo_name = \"subgraphs-{}-{}-{}{}\".format(\n",
    "        merge, split, subgraph, \"-smart\" if use_smart_split else \"\"\n",
    "    )\n",
    "    return (relabel, algo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_for_graph_class(\n",
    "    dataset_name: str,\n",
    "    graphs: Iterable[nx.Graph],\n",
    "    all_max_vertex_no: int,\n",
    "    rounds:int,\n",
    "    graph_timeout: int,\n",
    "    use_smart_split: bool = True,\n",
    "    use_monochromatic_classes: bool = True,\n",
    "    df_seen: pd.DataFrame | None | Callable[[], pd.DataFrame] = load_records,\n",
    "    save_every: int | None = 5*60,\n",
    "    cycles_all_max_vertices: int = 20,\n",
    "    cycles_first_max_vertices: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs benchmarks for the given graph class.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_name: Name of the dataset stored in the output csv\n",
    "        graphs: Iterable of graphs to benchmark\n",
    "        all_max_vertex_no: Maximum vertex number to search for all NAC-colorings\n",
    "        rounds: Number of rounds to run for each graph\n",
    "        graph_timeout: Timeout for each graph in seconds\n",
    "        use_monochromatic_classes: Whether to use monochromatic classes or tiriangle connected components\n",
    "        df_seen: Dataframe with already measured data, so already tried graphs and strategies can be skipped\n",
    "        save_every: save progress every number of seconds\n",
    "    \"\"\"\n",
    "    if callable(df_seen):\n",
    "        df_seen = df_seen()\n",
    "\n",
    "    dataset_name = dataset_name.replace(\" \", \"_\").lower()\n",
    "    if df_seen is None:\n",
    "        df_seen = new_DataFrame()\n",
    "    df_seen = df_seen.query(f\"dataset == '{dataset_name}'\")\n",
    "\n",
    "    results: List[MeasurementResult] = []\n",
    "    all_results: List[MeasurementResult] = []\n",
    "\n",
    "    last_save = time.time()\n",
    "\n",
    "    # def safe_iterator(graphs: Iterable[nx.Graph])->Iterator[nx.Graph]:\n",
    "    #     graphs = iter(graphs)\n",
    "    #     failures = 0\n",
    "    #     while failures < 128:\n",
    "    #         try:\n",
    "    #             graph = next(graphs, None)\n",
    "    #         except nx.NetworkXError as e:\n",
    "    #             print(e)\n",
    "    #             failures += 1\n",
    "    #             continue\n",
    "\n",
    "    #         if graph is None:\n",
    "    #             break\n",
    "    #         yield graph\n",
    "    # graphs = safe_iterator(graphs)\n",
    "\n",
    "    for graph in tqdm(graphs):\n",
    "        # this would be a functin if python would not have broken scoping\n",
    "        if save_every is not None and len(results) > 0:\n",
    "            now = time.time()\n",
    "            if now - last_save > save_every:\n",
    "                all_results.extend(results)\n",
    "                df = new_DataFrame(results)\n",
    "                update_stored_data([df], head_loaded=False)\n",
    "                results = []\n",
    "                last_save = now\n",
    "\n",
    "\n",
    "        all_colorings = all_max_vertex_no >= graph.number_of_nodes()\n",
    "        trianlge_classes = len(nac.find_monochromatic_classes(graph=graph, class_type=MonochromaticClassType.TRIANGLES)[1])\n",
    "        monochromatic_classes = len(nac.find_monochromatic_classes(graph=graph, class_type=MonochromaticClassType.MONOCHROMATIC)[1])\n",
    "\n",
    "        strategies = Promising.strategies_offline if all_colorings else Promising.strategies_online\n",
    "\n",
    "        # add cycle strategy\n",
    "        if (all_colorings and graph.number_of_nodes() < cycles_all_max_vertices) or (not all_colorings and graph.number_of_nodes() < cycles_first_max_vertices):\n",
    "            strategies = itertools.chain(strategies, [None])\n",
    "\n",
    "        graph_id = graph_to_id(graph)\n",
    "        df_graph = df_seen.query(f\"graph == '{graph_id}'\")\n",
    "\n",
    "        for strategy in strategies:\n",
    "            # skip test that already run\n",
    "            if strategy is not None:\n",
    "                prev_record = df_graph.query(\n",
    "                    f\"relabel == '{strategy[0]}'\"\n",
    "                    + f\" and split == '{strategy[1]}'\"\n",
    "                    + f\" and merging == '{strategy[2]}'\"\n",
    "                    + f\" and subgraph_size == {strategy[3]}\"\n",
    "                    + f\" and use_smart_split == {use_smart_split}\"\n",
    "                    + f\" and used_monochromatic_classes == {use_monochromatic_classes}\"\n",
    "                )\n",
    "            else:\n",
    "                prev_record = df_graph.query(\n",
    "                    f\"relabel == 'none'\"\n",
    "                    + f\" and split == 'naive-cycles'\"\n",
    "                    + f\" and merging == 'naive-cycles'\"\n",
    "                    + f\" and subgraph_size == 0\"\n",
    "                    + f\" and use_smart_split == {use_smart_split}\"\n",
    "                    + f\" and used_monochromatic_classes == {use_monochromatic_classes}\"\n",
    "                )\n",
    "            if len(prev_record) > 0:\n",
    "                # ensureds graphs are recomputed if all_max_vertex_no is increased\n",
    "                if graph.number_of_nodes() > all_max_vertex_no or list(prev_record[\"nac_all_mean_time\"])[-1] > 0:\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                # print(strategy)\n",
    "                search_res = nac_benchmark_core(\n",
    "                    graph,\n",
    "                    rounds=rounds,\n",
    "                    first_only=not all_colorings,\n",
    "                    strategy=create_strategy(strategy, use_smart_split=use_smart_split) if strategy else (\"none\", \"cycles\"),\n",
    "                    use_monochromatic_classes=use_monochromatic_classes,\n",
    "                    time_limit=graph_timeout,\n",
    "                )\n",
    "\n",
    "                relabel, split, merge, subgraph_size = strategy if strategy else (\"none\", \"naive-cycles\", \"naive-cycles\", 0)\n",
    "                res = create_measurement_result(\n",
    "                    graph=graph,\n",
    "                    dataset_name=dataset_name,\n",
    "                    trianlge_classes=trianlge_classes,\n",
    "                    monochromatic_classes=monochromatic_classes,\n",
    "                    nac_first=search_res.first,\n",
    "                    nac_all=search_res.all,\n",
    "                    relabel_strategy=relabel,\n",
    "                    split_strategy=split,\n",
    "                    merge_strategy=merge,\n",
    "                    subgraph_size=subgraph_size,\n",
    "                    use_smart_split=use_smart_split,\n",
    "                    used_monochromatic_classes=use_monochromatic_classes,\n",
    "                )\n",
    "                results.append(res)\n",
    "                # print(res.nac_first_mean_time)\n",
    "            except Exception as e:\n",
    "                print(f\"Exception for strategy {strategy}: {e}\")\n",
    "                # raise e\n",
    "\n",
    "    all_results.extend(results)\n",
    "    if len(all_results) == 0:\n",
    "        print(\"All runs skipped\")\n",
    "\n",
    "    if len(results) > 0:\n",
    "        df = new_DataFrame(results)\n",
    "        update_stored_data([df], head_loaded=False)\n",
    "\n",
    "    df = new_DataFrame(all_results)\n",
    "    df = df.sort_values(by=[\"nac_all_mean_time\", \"nac_first_mean_time\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    df_test = measure_for_graph_class(\n",
    "        \"test\",\n",
    "        # [g for g in Graphs.laman if g.number_of_nodes() == 8][:8],\n",
    "        [g for g in Graphs.laman_nauty if g.number_of_nodes() < 12][:32],\n",
    "        # [g for g in Graphs.laman_deg_3_plus if g.number_of_nodes() == 8][:8],\n",
    "        # [g for g in Graphs.sparse_graphs if g.number_of_nodes() == 13][:8],\n",
    "        # Graphs.sparse_graphs,\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "        df_seen=df_benchmarks,\n",
    "        save_every=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laman Nauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_laman = measure_for_graph_class(\n",
    "        \"Laman\",\n",
    "        Graphs.laman_nauty,\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laman Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_laman_random = measure_for_graph_class(\n",
    "        \"Laman random\",\n",
    "        Graphs.laman_random,\n",
    "        all_max_vertex_no=18,\n",
    "        rounds=2,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laman deg 3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_laman_deg_3_plus = measure_for_graph_class(\n",
    "        \"Laman deg 3+\",\n",
    "        Graphs.laman_deg_3_plus,\n",
    "        # All with 36 strtegies, 3 rounds\n",
    "        #  8 - 1s/it\n",
    "        #  9 - 1s/it\n",
    "        # 10 - 2s/it\n",
    "        # 11 - 7s/it\n",
    "        # 12 - 15s/it -> ~20 mon. classes\n",
    "        # First coloring with 27 strategies, 3 rounds\n",
    "        # 15 - 5s/it\n",
    "        # 16 - 5s/it\n",
    "        # 17 - 90s/it\n",
    "        all_max_vertex_no=12,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No 3 nor 4 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    display(pd.Series([g.number_of_nodes() for g in Graphs.no_3_nor_4_cycles]).value_counts())\n",
    "    df_no_3_nor_4_cycles = measure_for_graph_class(\n",
    "        \"No 3 nor 4 cycles\",\n",
    "        Graphs.no_3_nor_4_cycles,\n",
    "        # 24 strategies\n",
    "        # 10 - 5 s/it\n",
    "        # 11 - 10 s/it\n",
    "        # 12 - 28 s/it\n",
    "        # 13 -\n",
    "        all_max_vertex_no=0,\n",
    "        rounds=2,\n",
    "        graph_timeout=3,\n",
    "    )\n",
    "display(max(Graphs.no_3_nor_4_cycles, key=lambda g: g.number_of_nodes()).number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line graphs of no 3 nor 4 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    line_graphs = [\n",
    "        nx.convert_node_labels_to_integers(nx.line_graph(g))\n",
    "        for g in Graphs.no_3_nor_4_cycles\n",
    "        if max(deg for _, deg in g.degree) >= 3\n",
    "    ]\n",
    "\n",
    "    df_line_graphs_of_no_3_nor_4_cycles = measure_for_graph_class(\n",
    "        \"Line graph of no 3 nor 4 cycles\",\n",
    "        line_graphs,\n",
    "        all_max_vertex_no=13,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globally rigid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    df_benchmarks = load_records()\n",
    "    globary_rigid_dataset = df_benchmarks.query(\"dataset == 'globally_rigid'\")['graph'].unique()\n",
    "    globary_rigid_dataset = list(graph_from_id(id) for id in globary_rigid_dataset)\n",
    "    globary_rigid_dataset = pd.concat([globary_rigid_dataset, Graphs.globally_rigid,])\n",
    "\n",
    "    measure_for_graph_class(\n",
    "        \"globally_rigid\",\n",
    "        globary_rigid_dataset,\n",
    "        all_max_vertex_no=20,\n",
    "        rounds=2,\n",
    "        graph_timeout=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No NAC coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BENCHMARKS:\n",
    "    for name, df in {\n",
    "        \"no_NAC_coloring_generated_40\": Graphs.no_NAC_coloring_generated_40,\n",
    "        \"no_NAC_coloring_generated_50\": Graphs.no_NAC_coloring_generated_50,\n",
    "        \"no_NAC_coloring_generated_60\": Graphs.no_NAC_coloring_generated_60,\n",
    "        \"no_NAC_coloring_generated_70\": Graphs.no_NAC_coloring_generated_70,\n",
    "        \"no_NAC_coloring_generated_80\": Graphs.no_NAC_coloring_generated_80,\n",
    "        \"no_NAC_coloring_generated_90\": Graphs.no_NAC_coloring_generated_90,\n",
    "        \"no_NAC_coloring_generated_100\": Graphs.no_NAC_coloring_generated_100,\n",
    "        \"no_NAC_coloring_generated_110\": Graphs.no_NAC_coloring_generated_110,\n",
    "        \"no_NAC_coloring_generated_120\": Graphs.no_NAC_coloring_generated_120,\n",
    "        \"no_NAC_coloring_generated_130\": Graphs.no_NAC_coloring_generated_130,\n",
    "    }.items():\n",
    "        for smart_split in [False]:\n",
    "        # for smart_split in [False, True]:\n",
    "            print(name, smart_split)\n",
    "            measure_for_graph_class(\n",
    "                name,\n",
    "                df[:500],\n",
    "                all_max_vertex_no=0,\n",
    "                rounds=2,\n",
    "                graph_timeout=15,\n",
    "                cycles_first_max_vertices=0,\n",
    "                use_monochromatic_classes=False, # Most of the graphs have a single monochromatic class only -> it makes no sense for benchmarking\n",
    "                use_smart_split=smart_split,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather graphs with no NAC-coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_graph_class(\n",
    "    dataset_name: str,\n",
    "    name: str,\n",
    "):\n",
    "    df_benchmarks = load_records()\n",
    "    display(df_benchmarks[\"dataset\"].unique())\n",
    "    graphs = df_benchmarks.query(f\"nac_any_finished == True and dataset == '{dataset_name}'\")['graph'].drop_duplicates()\n",
    "    output_dir = f\"graphs_store/random\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    path = os.path.join(output_dir, f\"{name}.g6\")\n",
    "    lines = 0\n",
    "    with open(path, \"wb\") as f:\n",
    "        for graph in graphs:\n",
    "            lines += 1\n",
    "            graph = graph_from_id(graph)\n",
    "            # graph = nx.graph6.from_graph6_bytes(graph)\n",
    "            graph = nx.graph6.to_graph6_bytes(graph, header=False)\n",
    "            f.write(graph)\n",
    "    print(lines)\n",
    "\n",
    "def export_sparse_graphs_with_few_colorings():\n",
    "    graphs = [g for g, _ in zip(dataset.generate_NAC_critical_graphs(30, 60, seed=None), range(2000))]\n",
    "    output_dir = f\"graphs_store/random\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    name = \"test\"\n",
    "    path = os.path.join(output_dir, f\"{name}.g6\")\n",
    "    lines = 0\n",
    "    with open(path, \"wb\") as f:\n",
    "        for graph in graphs:\n",
    "            lines += 1\n",
    "            # graph = graph_from_id(graph)\n",
    "            # graph = nx.graph6.from_graph6_bytes(graph)\n",
    "            graph = nx.graph6.to_graph6_bytes(graph, header=False)\n",
    "            f.write(graph)\n",
    "    print(lines)\n",
    "\n",
    "def export_no_NAC_coloring():\n",
    "    df_benchmarks = load_records()\n",
    "    df = df_benchmarks.query(\"nac_any_finished == True and nac_first_coloring_no == 0 and triangle_components_no > 1\")\n",
    "    print(f\"Export from groups: {df[\"dataset\"].unique()}\")\n",
    "    graphs = df['graph'].drop_duplicates()\n",
    "\n",
    "    output_dir = f\"graphs_store/extracted\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    name = \"no_nac_coloring\"\n",
    "    path = os.path.join(output_dir, f\"{name}.g6\")\n",
    "    lines = 0\n",
    "    with open(path, \"wb\") as f:\n",
    "        for graph in graphs:\n",
    "            lines += 1\n",
    "            graph = graph_from_id(graph)\n",
    "            # graph = nx.graph6.from_graph6_bytes(graph)\n",
    "            graph = nx.graph6.to_graph6_bytes(graph, header=False)\n",
    "            f.write(graph)\n",
    "    print(lines)\n",
    "\n",
    "# export_no_NAC_coloring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics\n",
    "\n",
    "Base graphs show the time required to find\n",
    "a first/all NAC coloring based on vertex no./monochromatic classes no.\n",
    "First graphs are separated for each class of graphs and\n",
    "in the end for all the classes combined.\n",
    "Graphs are drawn for each strategy cathegory to compare them easily.\n",
    "Graphs show mean, median and 1st quartil values of running times to lower bias.\n",
    "\n",
    "Second group of graphs shows our contribution of decresing\n",
    "the number of `is_NAC_coloring` checks called compared to\n",
    "the naive approach without or with triangle/monochromatic classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_latex_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytics_loaded = load_records()\n",
    "df_analytics_loaded.set_index(\"graph\", inplace=True)\n",
    "df_analytics_loaded = df_analytics_loaded.query(\"dataset != 'test'\")\n",
    "display(df_analytics_loaded.columns)\n",
    "display(list(df_analytics_loaded[\"dataset\"].unique()))\n",
    "display(list(df_analytics_loaded[\"relabel\"].unique()))\n",
    "display(list(df_analytics_loaded[\"split\"].unique()))\n",
    "display(list(df_analytics_loaded[\"merging\"].unique()))\n",
    "\n",
    "# Transform\n",
    "df_analytics_loaded = df_analytics_loaded.assign(split_merging=lambda x: (x[\"split\"] + \" & \" + x[\"merging\"]).str.replace(\"naive-cycles & naive-cycles\", \"naive cycles\").str.replace(\"&\", r\"\\&\").str.replace(\"_\", r\"\\_\"))\n",
    "df_analytics_loaded = df_analytics_loaded.assign(split_merging_smart=lambda x: x[\"split_merging\"] + \" & \" + x[\"use_smart_split\"].astype(str))\n",
    "df_analytics_loaded.sort_values(by=\"split\", inplace=True, kind=\"stable\") # to make graph colors more regular\n",
    "df_analytics_loaded.sort_values(by=\"merging\", inplace=True, kind=\"stable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserver the original data\n",
    "df_analytics = df_analytics_loaded\n",
    "\n",
    "# Filter out trivial graphs\n",
    "df_analytics = df_analytics.query(\"(monochromatic_classes_no > 1 and used_monochromatic_classes == True) or (triangle_components_no > 1 and used_monochromatic_classes == False)\")\n",
    "\n",
    "# Filter bad strategies\n",
    "df_with_failing = df_analytics\n",
    "df_analytics = df_analytics.query(\"split == 'naive-cycles' or split == 'none' or split == 'neighbors' or split == 'neighbors_degree' or split=='cycles_match_chunks'\")\n",
    "df_analytics = df_analytics.query(\"merging == 'naive-cycles' or merging == 'linear' or merging == 'shared_vertices'\") #  or merging== 'score'\n",
    "# df_analytics = df_analytics.query(\"split != 'naive-cycles' and split != 'neighbors_degree' and split!='cycles_match_chunks'\")\n",
    "# df_analytics = df_analytics.query(\"merging != 'min_max' and merging != 'sorted_bits'\")\n",
    "\n",
    "# Graphs with no NAC coloring and more triangle connected components\n",
    "df_analytics_no_nac = df_analytics.query(\"nac_first_coloring_no == 0 and triangle_components_no > 1 and used_monochromatic_classes == False\")\n",
    "\n",
    "# Statistics\n",
    "def analyze_general(df: pd.DataFrame) -> None:\n",
    "    print(f\"Total runs: {len(df)}\", )\n",
    "    print(f\"Total graphs: {len(df.index.unique())}\")\n",
    "    df_finished = df.query(\"nac_any_finished == True\")\n",
    "    df_failed = df.query(\"nac_any_finished == False\")\n",
    "    print(f\"Runs that did/not/finish: {len(df_finished)}/{len(df_failed)}/{len(df)} ({np.round(len(df_failed)/len(df)*100, 1)}% did not finish)\")\n",
    "    print(f\"Graphs where some runs did/not/finish: {df_finished.index.nunique()}/{df_failed.index.nunique()}/{df.index.nunique()}\")\n",
    "\n",
    "def analyze_colorings(df: pd.DataFrame) -> None:\n",
    "    df_finished = df.query(\"nac_any_finished == True\")\n",
    "    print(f\"Graphs with  a NAC-coloring:\", df_finished.query(\"nac_first_coloring_no  > 0\").index.nunique())\n",
    "    print(f\"Graphs with no NAC-coloring:\", df_finished.query(\"nac_first_coloring_no == 0\").index.nunique())\n",
    "    print(f\"Graphs with no NAC-coloring and more monochromatic classes:\", df_finished.query(\"nac_first_coloring_no == 0 and monochromatic_classes_no > 1\").index.nunique())\n",
    "\n",
    "def analyze_finished(df: pd.DataFrame) -> None:\n",
    "    graphs = df.index.unique()\n",
    "    graphs_all_finished = filter_graphs_that_finished_for_all_strategies(df)\n",
    "    graphs_nonnaive_finished = filter_graphs_that_finished_for_all_strategies(df.query(\"split != 'naive-cycles'\"))\n",
    "    print(f\"{len(graphs_all_finished)}/{len(graphs)} graphs finished on all tested strategies.\")\n",
    "    print(f\"{len(graphs_nonnaive_finished)}/{len(graphs)} graphs finished on all tested strategies excluding naive cycles.\")\n",
    "\n",
    "    df_all_finished = df.loc[graphs_all_finished]\n",
    "    df_nonnaive_finished = df.loc[graphs_nonnaive_finished]\n",
    "    print(f\"Records corresponding to graph, that finished on all tested strategies: {len(df_all_finished)}\")\n",
    "    print(f\"Records corresponding to graph, that finished on all tested strategies excluding naive cycles: {len(df_nonnaive_finished)}\")\n",
    "\n",
    "\n",
    "print(\"All together:\")\n",
    "analyze_general(df_with_failing)\n",
    "print()\n",
    "\n",
    "print(\"Just preffered strategies:\")\n",
    "analyze_general(df_analytics)\n",
    "analyze_colorings(df_analytics)\n",
    "print()\n",
    "\n",
    "analyze_finished(df_analytics)\n",
    "\n",
    "df_analytics = replace_failed_results(df_analytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"globally_rigid\", \"minimally_rigid_random\", \"no_3_nor_4_cycles\", \"no_nac_coloring_generated_40\"]:\n",
    "    fig = plot_monochromatic_vs_triangle(df_analytics, dataset=dataset)\n",
    "    display(fig)\n",
    "    export_monochromatic_vs_triangle(fig, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random minimally rigid graphs Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False:\n",
    "    title = 'Laman random'\n",
    "    dataset_name = 'laman_random'\n",
    "    dataset = finished_graphs(df_analytics.query(f\"dataset == '{dataset_name}'\"))\n",
    "    figs = [fig for fig in plot_frame(title, dataset)]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    title = 'Minimally rigid'\n",
    "    dataset_name = 'minimally_rigid_random'\n",
    "    dataset = drop_outliers(finished_graphs(df_analytics.query(f\"dataset == '{dataset_name}'\")))\n",
    "    figs = [fig for fig in plot_frame(title, dataset, ops_value_columns_sets=[[\"nac_first_mean_time\"], [\"nac_first_check_cycle_mask\"]])]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)\n",
    "\n",
    "    dataset = drop_outliers(finished_graphs(df_analytics.query(f\"dataset == '{dataset_name}' and split != 'cycles_match_chunks'\")))\n",
    "    figs = [fig for fig in plot_frame(title, dataset, ops_value_columns_sets=[[\"nac_all_mean_time\"], [\"nac_all_check_cycle_mask\"]])]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False: # Not enough data yet\n",
    "    [display(fig) for fig in plot_frame(\"Laman deg 3+\", df_analytics.query(\"dataset == 'laman_deg_3+'\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No 3 nor 4 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    title = 'No 3 nor 4 cycles'\n",
    "    dataset_name = 'no_3_nor_4_cycles'\n",
    "\n",
    "    dataset = drop_outliers(finished_graphs_no_naive(df_analytics.query(f\"dataset == '{dataset_name}' and not (split == 'none' and merging=='shared_vertices' and vertex_no >= 50)\")))\n",
    "    figs = [fig for fig in plot_frame(title, dataset, Columns.first)]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)\n",
    "\n",
    "    dataset = drop_outliers(finished_graphs_no_naive(df_analytics.query(f\"dataset == '{dataset_name}'\")))\n",
    "    figs = [fig for fig in plot_frame(title, dataset, Columns.all)]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False: # Not enough data yet\n",
    "    [display(fig) for fig in plot_frame(\"Line graphs of no 3 nor 4 cycles\", df_analytics.query(\"dataset == 'line_graph_of_no_3_nor_4_cycles'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False:\n",
    "    [display(fig) for fig in plot_frame(\"Sparse\", df_analytics.query(\"dataset == 'sparse'\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores weird data - noisy and changing in unpredictible ways\n",
    "if ANALYTICS and False:\n",
    "    [display(fig) for fig in plot_frame(\"Few colorings - None\", df_analytics.query(\"dataset == 'few_colorings'\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globally Rigid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    title = 'Globally rigid'\n",
    "    dataset_name = 'globally_rigid'\n",
    "\n",
    "    dataset = drop_outliers(finished_graphs_no_naive(df_analytics.query(f\"dataset == '{dataset_name}'  and subgraph_size != 4\")))\n",
    "    figs = [fig for fig in plot_frame(title, dataset,\n",
    "        ops_value_columns_sets=Columns.first,\n",
    "        # ops_based_on=[\"subgraph_size\"],\n",
    "    )]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)\n",
    "\n",
    "    dataset = drop_outliers(finished_graphs_no_naive(df_analytics.query(f\"dataset == '{dataset_name}'\")))\n",
    "    figs = [fig for fig in plot_frame(title, dataset,\n",
    "        ops_value_columns_sets=Columns.all,\n",
    "        ops_x_column=[Columns.MONOCHROMATIC_CLASSES_NO],\n",
    "    )]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS and False:\n",
    "    [display(fig) for fig in plot_frame(\"No NAC-coloring gathered, ▵-components\", df_analytics_no_nac, ops_x_column = [\"vertex_no\", \"triangle_components_no\",],)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No NAC-coloring - generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_no_nac_coloring_generated(base: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = base.reset_index(inplace=False)\n",
    "    base = base.query(\"split != 'naive-cycles'\")\n",
    "    base_40 = base.query(\"dataset == 'no_nac_coloring_generated_40'\")\n",
    "    base_50 = base.query(\"dataset == 'no_nac_coloring_generated_50'\")\n",
    "    base_60 = base.query(\"dataset == 'no_nac_coloring_generated_60'\")\n",
    "    base_70 = base.query(\"dataset == 'no_nac_coloring_generated_70'\")\n",
    "    base_80 = base.query(\"dataset == 'no_nac_coloring_generated_80'\")\n",
    "    base_90 = base.query(\"dataset == 'no_nac_coloring_generated_90'\")\n",
    "    base_100 = base.query(\"dataset == 'no_nac_coloring_generated_100'\")\n",
    "    base_110 = base.query(\"dataset == 'no_nac_coloring_generated_110'\")\n",
    "    base_120 = base.query(\"dataset == 'no_nac_coloring_generated_120'\")\n",
    "    base_130 = base.query(\"dataset == 'no_nac_coloring_generated_130'\")\n",
    "    # df = base_40\n",
    "    df = pd.concat([base_40, base_50, base_60, base_70, base_80, base_90, base_100, base_110, base_120, base_130], ignore_index=True)\n",
    "    df.set_index(\"graph\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS or True:\n",
    "    base = df_analytics_no_nac\n",
    "    df = query_no_nac_coloring_generated(base)\n",
    "    df = drop_outliers(finished_graphs_no_naive(df))\n",
    "    title = 'No NAC-coloring, ▵-connected components'\n",
    "    dataset_name = 'no_nac_coloring_generated'\n",
    "\n",
    "    figs = [fig for fig in plot_frame(\n",
    "        title,\n",
    "        df.query(\"subgraph_size==4 or subgraph_size==5\"),\n",
    "        ops_x_column=[ \"vertex_no\",\"triangle_components_no\",],\n",
    "        ops_based_on=[\"split_merging\"],\n",
    "        filter_out_exhaustive_mergin_strategies_for_first=False,\n",
    "    )]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)\n",
    "\n",
    "    figs = [fig for fig in plot_frame(\n",
    "        title,\n",
    "        df.query(\"vertex_no<60\"),\n",
    "        ops_x_column=[ \"vertex_no\",\"triangle_components_no\",],\n",
    "        ops_based_on=[\"subgraph_size\"],\n",
    "        filter_out_exhaustive_mergin_strategies_for_first=False,\n",
    "    )]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failing 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    title = 'Minimally rigid'\n",
    "    # dataset_name = 'laman_random'\n",
    "    dataset_name = 'minimally_rigid_random'\n",
    "\n",
    "    dataset = drop_outliers(finished_graphs_no_naive(df_with_failing.query(f\"dataset == '{dataset_name}' and split == 'neighbors' and merging != 'score'\")))\n",
    "    figs = [fig for fig in plot_frame( title, dataset)]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name + \"_failing_merging\", figs)\n",
    "\n",
    "    dataset = drop_outliers(finished_graphs_no_naive(df_with_failing.query(f\"dataset == '{dataset_name}' and merging == 'linear'\")))\n",
    "    figs = [fig for fig in plot_frame( title,dataset)]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name + \"_failing_split\", figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    base = df_with_failing.query(\"subgraph_size==4 or subgraph_size==5\")\n",
    "    df = query_no_nac_coloring_generated(base)\n",
    "    title = 'No NAC-coloring'\n",
    "    cut_at = 70\n",
    "\n",
    "    dataset = drop_outliers(finished_graphs_no_naive(df.query(f\"split == 'neighbors' and vertex_no < {cut_at}\")))\n",
    "    figs = [fig for fig in plot_frame(\n",
    "        title, dataset,\n",
    "        ops_x_column=[ \"triangle_components_no\",], # \"vertex_no\"\n",
    "        filter_out_exhaustive_mergin_strategies_for_first=False,\n",
    "    )]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(\"no_nac_coloring_generated_failing_merging\", figs)\n",
    "\n",
    "    dataset = drop_outliers(finished_graphs_no_naive(df.query(f\"merging == 'linear' and vertex_no < {cut_at}\")))\n",
    "    figs = [fig for fig in plot_frame(\n",
    "        title, dataset,\n",
    "        ops_x_column=[ \"triangle_components_no\",], # \"vertex_no\"\n",
    "        filter_out_exhaustive_mergin_strategies_for_first=False,\n",
    "    )]\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(\"no_nac_coloring_generated_failing_split\", figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative number of checks performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYTICS:\n",
    "    figs = [fig for fig in plot_is_NAC_coloring_calls(df_analytics.query(\"(split != 'naive-cycles') and (used_monochromatic_classes==True)\"))]\n",
    "    title = 'All datasets'\n",
    "    dataset_name = 'check-comparision'\n",
    "    [display(fig) for fig in figs]\n",
    "    export_standard_figure_list(dataset_name, figs)\n",
    "    # [export_figure_impl(fig, dataset_name, \"first\", group_by, \"reduction\", \"checks\", \"mean+median\") for fig, group_by in zip(figs, [\"vertices\", \"monochromatic\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisson with naive approach\n",
    "\n",
    "In this section of benchmarks we run our algorithm on all the Laman graphs of specified size.\n",
    "The goal is to show the performance improvement over the previous SOTA - naive approach.\n",
    "For clarity and simplicity we use only a single strategy - `neighbors_degree` with `linear` merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_colorings_on_all_graphs(\n",
    "    dataset_name: str,\n",
    "    graphs: Callable[[], Iterable[nx.Graph]],\n",
    "    vertex_no: int,\n",
    "    algorithm: str = \"subgraphs-linear-neighbors_degree-4-smart\",\n",
    "    DIR: str = os.path.join(\"benchmarks\", \"results\", \"iteration\"),\n",
    "    time_log: str | None =  None\n",
    "):\n",
    "    os.makedirs(DIR, exist_ok=True)\n",
    "    time_log = time_log or os.path.join(DIR, \"log.csv\")\n",
    "\n",
    "    stats = defaultdict(int)\n",
    "    rand = random.Random(42)\n",
    "\n",
    "    # print(f\"Running {algorithm} on {len(graphs)} graphs with {vertex_no} vertices\")\n",
    "    print(f\"Running {algorithm} on graphs with {vertex_no} vertices\")\n",
    "    graphs = graphs()\n",
    "    start = time.time()\n",
    "    for graph in tqdm(graphs):\n",
    "        iterable = nac.NAC_colorings(\n",
    "            graph,\n",
    "            algorithm=algorithm,\n",
    "            relabel_strategy=\"none\",\n",
    "            use_decompositions=False,\n",
    "            use_has_coloring_check=False,\n",
    "            seed=rand.randint(0, 2**32 - 1),\n",
    "        )\n",
    "        counter = itertools.count()\n",
    "        deque(zip(iterable, counter), maxlen=0)\n",
    "        coloring_no = next(counter) // 2\n",
    "        stats[coloring_no] += 1\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"The operation took {int(1_000_000*(end-start))}s\")\n",
    "    with open(time_log, \"a\") as f:\n",
    "        print(f\"{vertex_no},{algorithm},{int(1000*(end-start))}\", file=f, flush=True)\n",
    "\n",
    "    data = np.array(list(stats.items()))\n",
    "    df = pd.DataFrame(data, columns=[\"coloring_cnt\", \"graph_cnt\"])\n",
    "    df.sort_values(by=\"coloring_cnt\", inplace=True)\n",
    "    df[\"graph_cnt\"]\n",
    "    print(\n",
    "        f\"Most colorings: {tuple(df.iloc[-1])}, Most common: {tuple(df.loc[df[\"graph_cnt\"].idxmax()])} (coloring_cnt, graph_cnt)\"\n",
    "    )\n",
    "    # print(df.tail(n=50))\n",
    "\n",
    "    df.to_csv(os.path.join(DIR, f\"{dataset_name}_{vertex_no}_{algorithm}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = list(dataset.load_laman_degree_3_plus_all(vertex_no))\n",
    "\n",
    "if False:\n",
    "    for n in list(range(7, 12 + 1)):\n",
    "        RUN_AS_BENCHMARK_NOT_JUST_FOR_THE_STATS = False\n",
    "        if RUN_AS_BENCHMARK_NOT_JUST_FOR_THE_STATS:\n",
    "            # TODO improve so the dataset is not loaded every time\n",
    "            graphs = lambda: list(dataset.load_laman_all(n))\n",
    "        else:\n",
    "            graphs = lambda: dataset.load_laman_all(n)\n",
    "\n",
    "        find_colorings_on_all_graphs(\"laman\", graphs, n,)\n",
    "        find_colorings_on_all_graphs(\"laman\", graphs, n, \"naive\") if n <= 10 else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
